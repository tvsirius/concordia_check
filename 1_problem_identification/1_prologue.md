
Here the steps that led me to this project and their further exploration

# Dream Idea of a Dream Project and the way to Concordia

*Long time ago in a galaxy far far away...*

- The general idea, is something like a AI theatre 
The engine will be ChatGPT + Langchain framework.
Imaging having an actor having a character, character core, memory of conversation and a database of known facts of the other persons
In the first stage the project will have the actor and a host (and the user)
everything is done through text (just like chatgpt) or even with voice
and user can either communicate with actor, or instruct the host on the matters of creating, changing and tuning the actor
host is some entity that leads the play.
the actors can be created from universe of cinema or theater or literature, or from scratch, or modified and tuned
now the process is not precise, so a user may want to make changes during the play
the play phase represent the character actor communication with the user
the switching between modes should be done withing one same prompt field  (imaging a theater director in repetition with actor, sometimes saying to the actor not the text of play, but the instructions)
there also could be AI generated images of actors, and some theatrical interface
the next stage allows for having several different actors, and different settings, and even maybe a some sort of short script.
the design of the play is also conducted with the host. so user can just watch the play, or interact, or change something during. on the absence of script there can be set some time limits for actors to improvise...
now I know we have a Characters in new ChatGPT plus, and they can be finetuned, and I have not tried it, and maybe this should be considered
they also presented the ability to make a finetuning using API (something that could come exactly in hand here)
other consideration is that all this is just something build on ChatGPT, and using prompts you can come so some basic play with some character (of course not to such extent)
other thing is constrains, as it is hard to imaging the complexity needed
this is the point where I am now about this idea, and I will really value your thought on this
Just want to add what comes to mind - the new idea of multiuser experience: each user have one actor, and system provides a 2D room like in a old video game, with some obstacles, and users can move their actors across. When actors are getting close, they start to interact. This idea could be fresh

- ...

- This Concordia is fantastic! Reading this paper light a spark of inspiration! I think we could go some way similar to our CDSP projects, so starting with problem identification. What we will try to experiment and for what goal should be the first question.
And yes, this could be the path to something great, like I presented before (theater idea) but I think it could be even more that that. And I agree, having answered the question why and for what, such project could have a purpose far more than creative experiment. Thank you for this and for advise about submission - think I will follow it )

- I was exploring Concordia and simple, but good (as it seems) idea visit to my mind today.
Concordia is a fantastic thing, and offer many insight, sparks inspiration for using it not only for social simulations. One can only imagine possible intersection with scenic art, psychology, science fiction and many more. Let's now not go this far. (I also wonder is there a visualization add-on to Concordia? :carousel_horse:)
Concordia general approach is to model living beings using LLM, and simulate virtual space inhabited by this beings. One of the main proposed application is the social modeling, simulation and predicting of some population.
So let's find out can we really relay on LLMs to simulate humans.
How true could be the results of such simulations? 
I think it is possible to find some real social simulations, held on population of medium size. We will look for that kind of simulations, that can be transformed into the Concordia virtual settings. And we will do it. See the results. Compare. Try some fine-tuning, if we come up with any. I believe we could find answers to our question.

